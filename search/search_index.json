{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome Welcome! This wiki has many tutorials and resources related to making scalable web systems. On the left is our navigation section that helps you find the content you need. If you need help finding something, use the search functionality!","title":"Welcome"},{"location":"#welcome","text":"Welcome! This wiki has many tutorials and resources related to making scalable web systems. On the left is our navigation section that helps you find the content you need. If you need help finding something, use the search functionality!","title":"Welcome"},{"location":"0-kubernetes/kubernetes-basics/","text":"kubernetes-basics Docker Introduction Kubernetes (K8s in short) is an open-source container orchestration platform introduced by Google in 2014. The platform\u2019s main purpose is to automate deployment and management (e.g., update, scaling, security, networking, auto-repair) of containerized application in large distributed computer clusters. To this end, the platform offers a number of API primitives, deployment options, networking, container and storage interfaces, built-in security, and other useful features. Author Abhinav Tripathy High Level Concepts Pods Pods are the smallest unit in kubernetes. Pods represent containers that are actually running. Nodes A collection of pods represent a node. Nodes are often a physical machine that are actually running the pods. Clusters A collection of nodes represent a cluster. Clusters are by geographic region, which is where all the compute resources are hosted in the cloud. Notes Often when working with kubernetes one does not really create the individual pods and by defauly they don't really have an external IP. As a devops engineer, one would define number of pods required and then for the node have a load balancer than balances traffic between the pods and the load balancer creates a static IP that one uses to access the service. Key Benefits Focus on Configuration The main benefit of kubernetes is that it allows you to use a yaml file to define the desired state of the application and kubernetes as a system and engine will make sure that that state is always ensured. This allows for less work and hassle for devops engineers is as self managed as possible. As part of configuration, one can define how many replica of pods one wants, these could be defined as minimum and maximum or an exact number. Further, one can define compute resources to be dedicated to the pod creation, exact memory and CPU allocation can be specified for the pods. One can be conservative in terms of resource allocation to save on costs, it all depends on how one defines the system requirements to kubernetes. Auto Repair Auto repair is a key feature in kubernetes. For example, if we want 2 pods always running on the minimum for an application and all of a sudden one pod goes down due to high memory usage/CPU usage, kubernetes will either restart or recreate the pod which will be specifically useful. This goes back to show how devops engineers need to focus on config and kubernetes will take care of the rest. Auto Scaling Kuberenetes is also really good for scaling and especially autoscaling. It can scale from 3 requests per second to 3 million requests per second very easily. It has autoscaling features that can be enabled from one command. For the use case of CYE, this might be useful if there is unexpected traffic, it can scale and create additional pods or even nodes if required. Acknowledgements Feedback If you have any feedback or comments or want to improve something, please open an issue on github here","title":"Kubernetes basics"},{"location":"0-kubernetes/kubernetes-basics/#kubernetes-basics","text":"Docker","title":"kubernetes-basics"},{"location":"0-kubernetes/kubernetes-basics/#introduction","text":"Kubernetes (K8s in short) is an open-source container orchestration platform introduced by Google in 2014. The platform\u2019s main purpose is to automate deployment and management (e.g., update, scaling, security, networking, auto-repair) of containerized application in large distributed computer clusters. To this end, the platform offers a number of API primitives, deployment options, networking, container and storage interfaces, built-in security, and other useful features.","title":"Introduction"},{"location":"0-kubernetes/kubernetes-basics/#author","text":"Abhinav Tripathy","title":"Author"},{"location":"0-kubernetes/kubernetes-basics/#high-level-concepts","text":"","title":"High Level Concepts"},{"location":"0-kubernetes/kubernetes-basics/#pods","text":"Pods are the smallest unit in kubernetes. Pods represent containers that are actually running.","title":"Pods"},{"location":"0-kubernetes/kubernetes-basics/#nodes","text":"A collection of pods represent a node. Nodes are often a physical machine that are actually running the pods.","title":"Nodes"},{"location":"0-kubernetes/kubernetes-basics/#clusters","text":"A collection of nodes represent a cluster. Clusters are by geographic region, which is where all the compute resources are hosted in the cloud.","title":"Clusters"},{"location":"0-kubernetes/kubernetes-basics/#notes","text":"Often when working with kubernetes one does not really create the individual pods and by defauly they don't really have an external IP. As a devops engineer, one would define number of pods required and then for the node have a load balancer than balances traffic between the pods and the load balancer creates a static IP that one uses to access the service.","title":"Notes"},{"location":"0-kubernetes/kubernetes-basics/#key-benefits","text":"","title":"Key Benefits"},{"location":"0-kubernetes/kubernetes-basics/#focus-on-configuration","text":"The main benefit of kubernetes is that it allows you to use a yaml file to define the desired state of the application and kubernetes as a system and engine will make sure that that state is always ensured. This allows for less work and hassle for devops engineers is as self managed as possible. As part of configuration, one can define how many replica of pods one wants, these could be defined as minimum and maximum or an exact number. Further, one can define compute resources to be dedicated to the pod creation, exact memory and CPU allocation can be specified for the pods. One can be conservative in terms of resource allocation to save on costs, it all depends on how one defines the system requirements to kubernetes.","title":"Focus on Configuration"},{"location":"0-kubernetes/kubernetes-basics/#auto-repair","text":"Auto repair is a key feature in kubernetes. For example, if we want 2 pods always running on the minimum for an application and all of a sudden one pod goes down due to high memory usage/CPU usage, kubernetes will either restart or recreate the pod which will be specifically useful. This goes back to show how devops engineers need to focus on config and kubernetes will take care of the rest.","title":"Auto Repair"},{"location":"0-kubernetes/kubernetes-basics/#auto-scaling","text":"Kuberenetes is also really good for scaling and especially autoscaling. It can scale from 3 requests per second to 3 million requests per second very easily. It has autoscaling features that can be enabled from one command. For the use case of CYE, this might be useful if there is unexpected traffic, it can scale and create additional pods or even nodes if required.","title":"Auto Scaling"},{"location":"0-kubernetes/kubernetes-basics/#acknowledgements","text":"","title":"Acknowledgements"},{"location":"0-kubernetes/kubernetes-basics/#feedback","text":"If you have any feedback or comments or want to improve something, please open an issue on github here","title":"Feedback"},{"location":"0-kubernetes/kubernetes-system-design/","text":"Kubernetes-System-Design Author Abhinav Tripathy Linkedin Introduction When it comes to building scalable systems, kubernetes is a great tool and a quite a popular one. However, there are many fundamental concepts that one needs to think about from a system design perspective when thinking about scalable systems in the context of kubernetes. This tutorial hopes to cover some of the fundamental concepts such as databases, caching, the CAP theorem. The CAP Theorem CAP stands for: CAP: Consistency, Availability, Partition Tolerance Let us define these terms: - Consistency: any read operation that begins after a write operation completes must return that value, or the result of a later write operation - Availability: every request received by a non-failing node in the system must result in a response - Partition Tolerance: the network will be allowed to lose arbitrarily many messages sent from one node to another The theorem: The CAP theorem states that a distributed system cannot simultaneously be consistent, available, and partition tolerant. An illustrated proof of the theorem. An Example: In order to get both availability and partition tolerance, you have to give up consistency. Consider if you have two nodes, X and Y. Now, there is a break between network communication between X and Y, so they can't sync updates. At this point you can either: A) Allow the nodes to get out of sync (giving up consistency), or B) Consider the cluster to be \"down\" (giving up availability) The different combinations in CAP: CA - data is consistent between all nodes - as long as all nodes are online - and you can read/write from any node and be sure that the data is the same, but if you ever develop a partition between nodes, the data will be out of sync (and won't re-sync once the partition is resolved). CP - data is consistent between all nodes, and maintains partition tolerance (preventing data desync) by becoming unavailable when a node goes down. AP - nodes remain online even if they can't communicate with each other and will resync data once the partition is resolved, but you aren't guaranteed that all nodes will have the same data (either during or after the partition) An image displaying the proof: Important Note : CAP is a spectrum. What that means is that it is not a hard and fast rule that only 2 out of the 3 will work but rather it is a theorem to think about tradeoffs. Certain transactions require high availability some require high consistency. It helps a system designer to think about trade offs, optimize for these 3 important constraints. Single Point of Failure (SPOF) In any scalable system, we must avoid single point of failures. As the name suggests, it is a a node,(it could be any part of the system) if it fails the whole system would go down. As an example, this image displays how a single load balancer could be an SPOF. As the image suggests, having multiple load balancers is the solution. To mitigate SPOFs we have 3 key approaches: More Nodes: With more nodes one can duplicate the node or service and distribute traffic among them. Another way is to use the secondary node/nodes as a backup service, though that would potentially lead to wasting resources. Master Slave Approach: This approach is quite useful especially in the context of databases. The main question here is what if a database goes down. This can be mitigated by having a master database off which slaves replicate. So in the case master goes down, one of the slaves can become a master. There can be additional complexity such as having multiple masters or having read only slaves/write only slaves. Master - Master Approach: This is like the master slave approach however in this case the two or more nodes, all get read requests and write loads are distributed among the master nodes. The advantage it is a simple automatic failover. The main disadvatange is that it is loosely consistent and it is not as simple as master-slave to configure. Multiple Regions: Having all resources in one region can also mean a SPOF. For instance, all your services in the cloud are in the US east region. To avoid, infrastructure going down in one area or a natural disaster happenning, having services and resources split across multiple regions is a good practice. An Example Diagram of master slave approach: Databases The following are some key concepts in databases. ACID Compliance Atomicity : Database transactions, like atoms, can be broken down into smaller parts. When it comes to your database, atomicity refers to the integrity of the entire database transaction, not just a component of it. In other words, if one part of a transaction doesn\u2019t work like it\u2019s supposed to, the other will fail as a result\u2014and vice versa. For example, if you\u2019re shopping on an e-commerce site, you must have an item in your cart in order to pay for it. What you can\u2019t do is pay for something that\u2019s not in your cart. (You can add something into your cart and not pay for it, but that database transaction won\u2019t be complete, and thus not \u2018atomic\u2019, until you pay for it). Consistency : For any database to operate as it\u2019s intended to operate, it must follow the appropriate data validation rules. Thus, consistency means that only data which follows those rules is permitted to be written to the database. If a transaction occurs and results in data that does not follow the rules of the database, it will be \u2018rolled back\u2019 to a previous iteration of itself (or \u2018state\u2019) which complies with the rules. On the other hand, following a successful transaction, new data will be added to the database and the resulting state will be consistent with existing rules. Isolation : It\u2019s safe to say that at any given time on Amazon, there is far more than one transaction occurring on the platform. In fact, an incredibly huge amount of database transactions are occurring simultaneously. For a database, isolation refers to the ability to concurrently process multiple transactions in a way that one does not affect another. So, imagine you and your neighbor are both trying to buy something from the same e-commerce platform at the same time. There are 10 items for sale: your neighbor wants five and you want six. Isolation means that one of those transactions would be completed ahead of the other one. In other words, if your neighbor clicked first, they will get five items, and only five items will be remaining in stock. So you will only get to buy five items. If you clicked first, you will get the six items you want, and they will only get four. Thus, isolation ensures that eleven items aren\u2019t sold when only ten exist. Durability : All technology fails from time to time\u2026 the goal is to make those failures invisible to the end-user. In databases that possess durability, data is saved once a transaction is completed, even if a power outage or system failure occurs. Imagine you\u2019re buying in-demand concert tickets on a site similar to Ticketmaster.com. Right when tickets go on sale, you\u2019re ready to make a purchase. After being stuck in the digital waiting room for some time, you\u2019re finally able to add those tickets to your cart. You then make the purchase and get your confirmation. However if that database lacks durability, even after your ticket purchase was confirmed, if the database suffers a failure incident your transaction would still be lost! As you might expect, this is a really bad thing to happen for an online e-commerce site, so transaction durability is a must-have. Database Sharding Database sharding is a popular concept when dealing with high volume data and is a very popular way to manage in No-SQL databases. Shards are autonomous and is an example to scale horizontally. Shards are basically partitions of the database based on a key. This key is what decides the shards, it could be a column value, it could be location or user ID or any other attribute that makes sense and works universally on the incoming data. Each shard can be protected by the master slave architecture for further scalability. An example of shards: Caching Caching is a way to speed up retrieval of frequently or commonly accessed data. This means storing data in something like Redis that helps retrieve data very quickly. The reason this is possible is the data is stored in memory instead of a storage device like a disk(which is slower than in memory). In memory storage also means it is volatile which means it does not have ACID compliance. Advantages of Caching Reduce network calls Reduce Recomputations Reduce Database load Caching Policies Caching policies are used to delete unnecessary cache values to make sure the cache is up to date and always fresh and relevant to the incoming requests. LRU Cache - Least Recently Used LFU Cache - Least Frequently Used Cache Sliding window Updating the Cache Cache Aside Write Through Write Behind Refresh Ahead Storing Images Storing it as a file (in a file system) Storing files in a file system is often cheaper in the context of cost Database needs to be used to the save the file URL it is a static asset so can be used with CDNs - allows fast access Storing it in a database (as a Blob) Blob: Binary Large Object Storing the image as a blog in a database means there is ACID compliance which gives transaction garrantuees Indexes with databases can improve search Easy Access control with databases for images is quite useufl too Queue Systems Queues are used to in many scalable and distributed systems. They allow for asychronous tasks and environment to be handled which allows for better performance. It also makes a scalable system more fault tolerant as it acts as an intermediary between services. They also allow for very high throughput and scalability. Publisher Subscriber Model Often queues will be used through a publisher subscriber model. For Example, if we have a pizza delivery system, the client on the front-end acts as a publisher i.e. it publishes orders on to the queue. Then a service that notifies the team aobut the order is a subscriber. There can be mulitple subscribers and producers and a service can act as both. Sample Publisher Subscriber Model: More generall we can say that the model looks like the following: Message Guarantees In any system, we need to think about potential tradeoffs and guarantees. In queueing systems, one thing to talk about is processing/messaging guarantees. No guarantee \u2014 No explicit guarantee is provided, so consumers may process messages once, multiple times or never at all. At most once \u2014 This is \u201cbest effort\u201d delivery semantics. Consumers will receive and process messages exactly once or not at all. At least once \u2014 Consumers will receive and process every message, but they may process the same message more than once. Effectively once \u2014 Also contentiously known as exactly once, this promises consumers will process every message once. API Gateway An API Gateway is the entry door for a client to talk to a collection of backend services. The gateway provides a single entrypoint which allows it to look for the right services to talk to in the backend the return the approporiate result. API Gateway Architecture: Uses for API Gateway: - Rate Limiting - Statistics & User Analytics - Handling User Authentication - Handling multiple requests in a microservices architecture Acknowledgements CAP Updating cache Message Processing Guarantees Feedback If you have any feedback or comments or want to improve something, please open an issue on github here","title":"Kubernetes system design"},{"location":"0-kubernetes/kubernetes-system-design/#kubernetes-system-design","text":"","title":"Kubernetes-System-Design"},{"location":"0-kubernetes/kubernetes-system-design/#author","text":"Abhinav Tripathy Linkedin","title":"Author"},{"location":"0-kubernetes/kubernetes-system-design/#introduction","text":"When it comes to building scalable systems, kubernetes is a great tool and a quite a popular one. However, there are many fundamental concepts that one needs to think about from a system design perspective when thinking about scalable systems in the context of kubernetes. This tutorial hopes to cover some of the fundamental concepts such as databases, caching, the CAP theorem.","title":"Introduction"},{"location":"0-kubernetes/kubernetes-system-design/#the-cap-theorem","text":"CAP stands for: CAP: Consistency, Availability, Partition Tolerance Let us define these terms: - Consistency: any read operation that begins after a write operation completes must return that value, or the result of a later write operation - Availability: every request received by a non-failing node in the system must result in a response - Partition Tolerance: the network will be allowed to lose arbitrarily many messages sent from one node to another The theorem: The CAP theorem states that a distributed system cannot simultaneously be consistent, available, and partition tolerant. An illustrated proof of the theorem. An Example: In order to get both availability and partition tolerance, you have to give up consistency. Consider if you have two nodes, X and Y. Now, there is a break between network communication between X and Y, so they can't sync updates. At this point you can either: A) Allow the nodes to get out of sync (giving up consistency), or B) Consider the cluster to be \"down\" (giving up availability) The different combinations in CAP: CA - data is consistent between all nodes - as long as all nodes are online - and you can read/write from any node and be sure that the data is the same, but if you ever develop a partition between nodes, the data will be out of sync (and won't re-sync once the partition is resolved). CP - data is consistent between all nodes, and maintains partition tolerance (preventing data desync) by becoming unavailable when a node goes down. AP - nodes remain online even if they can't communicate with each other and will resync data once the partition is resolved, but you aren't guaranteed that all nodes will have the same data (either during or after the partition) An image displaying the proof: Important Note : CAP is a spectrum. What that means is that it is not a hard and fast rule that only 2 out of the 3 will work but rather it is a theorem to think about tradeoffs. Certain transactions require high availability some require high consistency. It helps a system designer to think about trade offs, optimize for these 3 important constraints.","title":"The CAP Theorem"},{"location":"0-kubernetes/kubernetes-system-design/#single-point-of-failure-spof","text":"In any scalable system, we must avoid single point of failures. As the name suggests, it is a a node,(it could be any part of the system) if it fails the whole system would go down. As an example, this image displays how a single load balancer could be an SPOF. As the image suggests, having multiple load balancers is the solution. To mitigate SPOFs we have 3 key approaches: More Nodes: With more nodes one can duplicate the node or service and distribute traffic among them. Another way is to use the secondary node/nodes as a backup service, though that would potentially lead to wasting resources. Master Slave Approach: This approach is quite useful especially in the context of databases. The main question here is what if a database goes down. This can be mitigated by having a master database off which slaves replicate. So in the case master goes down, one of the slaves can become a master. There can be additional complexity such as having multiple masters or having read only slaves/write only slaves. Master - Master Approach: This is like the master slave approach however in this case the two or more nodes, all get read requests and write loads are distributed among the master nodes. The advantage it is a simple automatic failover. The main disadvatange is that it is loosely consistent and it is not as simple as master-slave to configure. Multiple Regions: Having all resources in one region can also mean a SPOF. For instance, all your services in the cloud are in the US east region. To avoid, infrastructure going down in one area or a natural disaster happenning, having services and resources split across multiple regions is a good practice. An Example Diagram of master slave approach:","title":"Single Point of Failure (SPOF)"},{"location":"0-kubernetes/kubernetes-system-design/#databases","text":"The following are some key concepts in databases.","title":"Databases"},{"location":"0-kubernetes/kubernetes-system-design/#acid-compliance","text":"Atomicity : Database transactions, like atoms, can be broken down into smaller parts. When it comes to your database, atomicity refers to the integrity of the entire database transaction, not just a component of it. In other words, if one part of a transaction doesn\u2019t work like it\u2019s supposed to, the other will fail as a result\u2014and vice versa. For example, if you\u2019re shopping on an e-commerce site, you must have an item in your cart in order to pay for it. What you can\u2019t do is pay for something that\u2019s not in your cart. (You can add something into your cart and not pay for it, but that database transaction won\u2019t be complete, and thus not \u2018atomic\u2019, until you pay for it). Consistency : For any database to operate as it\u2019s intended to operate, it must follow the appropriate data validation rules. Thus, consistency means that only data which follows those rules is permitted to be written to the database. If a transaction occurs and results in data that does not follow the rules of the database, it will be \u2018rolled back\u2019 to a previous iteration of itself (or \u2018state\u2019) which complies with the rules. On the other hand, following a successful transaction, new data will be added to the database and the resulting state will be consistent with existing rules. Isolation : It\u2019s safe to say that at any given time on Amazon, there is far more than one transaction occurring on the platform. In fact, an incredibly huge amount of database transactions are occurring simultaneously. For a database, isolation refers to the ability to concurrently process multiple transactions in a way that one does not affect another. So, imagine you and your neighbor are both trying to buy something from the same e-commerce platform at the same time. There are 10 items for sale: your neighbor wants five and you want six. Isolation means that one of those transactions would be completed ahead of the other one. In other words, if your neighbor clicked first, they will get five items, and only five items will be remaining in stock. So you will only get to buy five items. If you clicked first, you will get the six items you want, and they will only get four. Thus, isolation ensures that eleven items aren\u2019t sold when only ten exist. Durability : All technology fails from time to time\u2026 the goal is to make those failures invisible to the end-user. In databases that possess durability, data is saved once a transaction is completed, even if a power outage or system failure occurs. Imagine you\u2019re buying in-demand concert tickets on a site similar to Ticketmaster.com. Right when tickets go on sale, you\u2019re ready to make a purchase. After being stuck in the digital waiting room for some time, you\u2019re finally able to add those tickets to your cart. You then make the purchase and get your confirmation. However if that database lacks durability, even after your ticket purchase was confirmed, if the database suffers a failure incident your transaction would still be lost! As you might expect, this is a really bad thing to happen for an online e-commerce site, so transaction durability is a must-have.","title":"ACID Compliance"},{"location":"0-kubernetes/kubernetes-system-design/#database-sharding","text":"Database sharding is a popular concept when dealing with high volume data and is a very popular way to manage in No-SQL databases. Shards are autonomous and is an example to scale horizontally. Shards are basically partitions of the database based on a key. This key is what decides the shards, it could be a column value, it could be location or user ID or any other attribute that makes sense and works universally on the incoming data. Each shard can be protected by the master slave architecture for further scalability. An example of shards:","title":"Database Sharding"},{"location":"0-kubernetes/kubernetes-system-design/#caching","text":"Caching is a way to speed up retrieval of frequently or commonly accessed data. This means storing data in something like Redis that helps retrieve data very quickly. The reason this is possible is the data is stored in memory instead of a storage device like a disk(which is slower than in memory). In memory storage also means it is volatile which means it does not have ACID compliance.","title":"Caching"},{"location":"0-kubernetes/kubernetes-system-design/#advantages-of-caching","text":"Reduce network calls Reduce Recomputations Reduce Database load","title":"Advantages of Caching"},{"location":"0-kubernetes/kubernetes-system-design/#caching-policies","text":"Caching policies are used to delete unnecessary cache values to make sure the cache is up to date and always fresh and relevant to the incoming requests. LRU Cache - Least Recently Used LFU Cache - Least Frequently Used Cache Sliding window","title":"Caching Policies"},{"location":"0-kubernetes/kubernetes-system-design/#updating-the-cache","text":"Cache Aside Write Through Write Behind Refresh Ahead","title":"Updating the Cache"},{"location":"0-kubernetes/kubernetes-system-design/#storing-images","text":"","title":"Storing Images"},{"location":"0-kubernetes/kubernetes-system-design/#storing-it-as-a-file-in-a-file-system","text":"Storing files in a file system is often cheaper in the context of cost Database needs to be used to the save the file URL it is a static asset so can be used with CDNs - allows fast access","title":"Storing it as a file (in a file system)"},{"location":"0-kubernetes/kubernetes-system-design/#storing-it-in-a-database-as-a-blob","text":"Blob: Binary Large Object Storing the image as a blog in a database means there is ACID compliance which gives transaction garrantuees Indexes with databases can improve search Easy Access control with databases for images is quite useufl too","title":"Storing it in a database (as a Blob)"},{"location":"0-kubernetes/kubernetes-system-design/#queue-systems","text":"Queues are used to in many scalable and distributed systems. They allow for asychronous tasks and environment to be handled which allows for better performance. It also makes a scalable system more fault tolerant as it acts as an intermediary between services. They also allow for very high throughput and scalability.","title":"Queue Systems"},{"location":"0-kubernetes/kubernetes-system-design/#publisher-subscriber-model","text":"Often queues will be used through a publisher subscriber model. For Example, if we have a pizza delivery system, the client on the front-end acts as a publisher i.e. it publishes orders on to the queue. Then a service that notifies the team aobut the order is a subscriber. There can be mulitple subscribers and producers and a service can act as both. Sample Publisher Subscriber Model: More generall we can say that the model looks like the following:","title":"Publisher Subscriber Model"},{"location":"0-kubernetes/kubernetes-system-design/#message-guarantees","text":"In any system, we need to think about potential tradeoffs and guarantees. In queueing systems, one thing to talk about is processing/messaging guarantees. No guarantee \u2014 No explicit guarantee is provided, so consumers may process messages once, multiple times or never at all. At most once \u2014 This is \u201cbest effort\u201d delivery semantics. Consumers will receive and process messages exactly once or not at all. At least once \u2014 Consumers will receive and process every message, but they may process the same message more than once. Effectively once \u2014 Also contentiously known as exactly once, this promises consumers will process every message once.","title":"Message Guarantees"},{"location":"0-kubernetes/kubernetes-system-design/#api-gateway","text":"An API Gateway is the entry door for a client to talk to a collection of backend services. The gateway provides a single entrypoint which allows it to look for the right services to talk to in the backend the return the approporiate result. API Gateway Architecture: Uses for API Gateway: - Rate Limiting - Statistics & User Analytics - Handling User Authentication - Handling multiple requests in a microservices architecture","title":"API Gateway"},{"location":"0-kubernetes/kubernetes-system-design/#acknowledgements","text":"CAP Updating cache Message Processing Guarantees","title":"Acknowledgements"},{"location":"0-kubernetes/kubernetes-system-design/#feedback","text":"If you have any feedback or comments or want to improve something, please open an issue on github here","title":"Feedback"}]}